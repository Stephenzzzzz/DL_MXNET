{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:38:16.551975Z",
     "start_time": "2019-05-14T08:38:15.826915Z"
    }
   },
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "\n",
    "def dropout(X, drop_prob):\n",
    "    # 断言drop_prob在0-1之间就执行后面的代码\n",
    "    assert 0 <= drop_prob <= 1\n",
    "    keep_prob = 1 - drop_prob\n",
    "    # 这种情况下把全部元素都丢弃，即drop_prob=1\n",
    "    if keep_prob == 0:\n",
    "        return X.zeros_like()\n",
    "    # 随机取0-1之间的数，形状和X一样，每个数和keep_prob比大小，比它小是1，否则0\n",
    "    # mask是一个只包含0，1，形状和X一样的矩阵\n",
    "    mask = nd.random.uniform(0, 1, X.shape) < keep_prob\n",
    "    # mask * X 把X里随机的数x0淘汰了，剩下x1的数还要再除以keep_prob拉伸一下\n",
    "    return mask * X / keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:40:11.567461Z",
     "start_time": "2019-05-14T08:40:11.553497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
       " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
       "<NDArray 2x8 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.arange(16).reshape((2, 8))\n",
    "dropout(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:40:17.810445Z",
     "start_time": "2019-05-14T08:40:17.803471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  2.  4.  6.  0.  0.  0. 14.]\n",
       " [ 0. 18.  0.  0. 24. 26. 28.  0.]]\n",
       "<NDArray 2x8 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:40:23.230305Z",
     "start_time": "2019-05-14T08:40:23.226281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       "<NDArray 2x8 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:43:12.320222Z",
     "start_time": "2019-05-14T08:43:12.313240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0.]\n",
       " [1. 0.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.arange(16).reshape((2, 8))\n",
    "nd.random.uniform(0, 1, (2,2)) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:51:36.017462Z",
     "start_time": "2019-05-14T08:51:36.009484Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "\n",
    "W1 = nd.random.normal(scale=0.01, shape=(num_inputs, num_hiddens1))\n",
    "b1 = nd.zeros(num_hiddens1)\n",
    "W2 = nd.random.normal(scale=0.01, shape=(num_hiddens1, num_hiddens2))\n",
    "b2 = nd.zeros(num_hiddens2)\n",
    "W3 = nd.random.normal(scale=0.01, shape=(num_hiddens2, num_outputs))\n",
    "b3 = nd.zeros(num_outputs)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:53:29.517868Z",
     "start_time": "2019-05-14T08:53:29.512882Z"
    }
   },
   "outputs": [],
   "source": [
    "# 通常的建议是把靠近输入层的丢弃概率设得小一点\n",
    "drop_prob1, drop_prob2 = 0.2, 0.5\n",
    "\n",
    "def net(X):\n",
    "    X = X.reshape((-1, num_inputs))\n",
    "    H1 = (nd.dot(X, W1) + b1).relu()\n",
    "    if autograd.is_training():  # 只在训练模型时使用丢弃法\n",
    "        H1 = dropout(H1, drop_prob1)  # 在第一层全连接后添加丢弃层\n",
    "    H2 = (nd.dot(H1, W2) + b2).relu()\n",
    "    if autograd.is_training(): # 只在训练模型时使用丢弃法\n",
    "        H2 = dropout(H2, drop_prob2)  # 在第二层全连接后添加丢弃层\n",
    "    return nd.dot(H2, W3) + b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:54:26.551443Z",
     "start_time": "2019-05-14T08:53:50.577658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.2214, train acc 0.528, test acc 0.768\n",
      "epoch 2, loss 0.6021, train acc 0.776, test acc 0.834\n",
      "epoch 3, loss 0.5061, train acc 0.814, test acc 0.850\n",
      "epoch 4, loss 0.4535, train acc 0.835, test acc 0.845\n",
      "epoch 5, loss 0.4280, train acc 0.843, test acc 0.864\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr, batch_size = 5, 0.5, 256\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:55:29.528023Z",
     "start_time": "2019-05-14T08:55:29.521040Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.2),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.5),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:56:32.746937Z",
     "start_time": "2019-05-14T08:56:00.945140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.2017, train acc 0.536, test acc 0.762\n",
      "epoch 2, loss 0.5930, train acc 0.780, test acc 0.835\n",
      "epoch 3, loss 0.5007, train acc 0.817, test acc 0.849\n",
      "epoch 4, loss 0.4581, train acc 0.833, test acc 0.860\n",
      "epoch 5, loss 0.4249, train acc 0.846, test acc 0.868\n"
     ]
    }
   ],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 我们可以通过使用丢弃法应对过拟合。\n",
    "* 丢弃法只在训练模型时使用。\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 如果把本节中的两个丢弃概率超参数对调，会有什么结果？\n",
    "* 增大迭代周期数，比较使用丢弃法与不使用丢弃法的结果。\n",
    "* 如果将模型改得更加复杂，如增加隐藏层单元，使用丢弃法应对过拟合的效果是否更加明显？\n",
    "* 以本节中的模型为例，比较使用丢弃法与权重衰减的效果。如果同时使用丢弃法和权重衰减，效果会如何？"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "调参测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T08:58:32.133303Z",
     "start_time": "2019-05-14T08:58:00.090751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1552, train acc 0.546, test acc 0.732\n",
      "epoch 2, loss 0.6035, train acc 0.774, test acc 0.826\n",
      "epoch 3, loss 0.5197, train acc 0.808, test acc 0.846\n",
      "epoch 4, loss 0.4755, train acc 0.824, test acc 0.857\n",
      "epoch 5, loss 0.4478, train acc 0.834, test acc 0.863\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.5),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.2),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T09:02:50.252895Z",
     "start_time": "2019-05-14T08:59:52.371352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1848, train acc 0.539, test acc 0.782\n",
      "epoch 2, loss 0.5565, train acc 0.790, test acc 0.839\n",
      "epoch 3, loss 0.4637, train acc 0.830, test acc 0.843\n",
      "epoch 4, loss 0.4151, train acc 0.846, test acc 0.858\n",
      "epoch 5, loss 0.3848, train acc 0.857, test acc 0.843\n",
      "epoch 6, loss 0.3702, train acc 0.863, test acc 0.867\n",
      "epoch 7, loss 0.3475, train acc 0.871, test acc 0.879\n",
      "epoch 8, loss 0.3332, train acc 0.876, test acc 0.880\n",
      "epoch 9, loss 0.3277, train acc 0.879, test acc 0.876\n",
      "epoch 10, loss 0.3154, train acc 0.882, test acc 0.877\n",
      "epoch 11, loss 0.3009, train acc 0.887, test acc 0.885\n",
      "epoch 12, loss 0.2922, train acc 0.890, test acc 0.878\n",
      "epoch 13, loss 0.2830, train acc 0.893, test acc 0.887\n",
      "epoch 14, loss 0.2783, train acc 0.897, test acc 0.885\n",
      "epoch 15, loss 0.2729, train acc 0.897, test acc 0.882\n",
      "epoch 16, loss 0.2680, train acc 0.899, test acc 0.884\n",
      "epoch 17, loss 0.2564, train acc 0.904, test acc 0.889\n",
      "epoch 18, loss 0.2523, train acc 0.905, test acc 0.883\n",
      "epoch 19, loss 0.2472, train acc 0.906, test acc 0.886\n",
      "epoch 20, loss 0.2385, train acc 0.909, test acc 0.887\n",
      "epoch 21, loss 0.2333, train acc 0.912, test acc 0.890\n",
      "epoch 22, loss 0.2329, train acc 0.912, test acc 0.886\n",
      "epoch 23, loss 0.2222, train acc 0.915, test acc 0.890\n",
      "epoch 24, loss 0.2216, train acc 0.917, test acc 0.892\n",
      "epoch 25, loss 0.2180, train acc 0.917, test acc 0.894\n",
      "epoch 26, loss 0.2172, train acc 0.916, test acc 0.893\n",
      "epoch 27, loss 0.2095, train acc 0.921, test acc 0.895\n",
      "epoch 28, loss 0.2052, train acc 0.922, test acc 0.894\n",
      "epoch 29, loss 257588.2725, train acc 0.425, test acc 0.100\n",
      "epoch 30, loss 2.3013, train acc 0.098, test acc 0.196\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"), \n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, 30, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T09:06:49.186192Z",
     "start_time": "2019-05-14T09:03:31.530434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1040, train acc 0.572, test acc 0.785\n",
      "epoch 2, loss 0.5757, train acc 0.788, test acc 0.830\n",
      "epoch 3, loss 0.4928, train acc 0.821, test acc 0.843\n",
      "epoch 4, loss 0.4389, train acc 0.840, test acc 0.859\n",
      "epoch 5, loss 0.4141, train acc 0.850, test acc 0.855\n",
      "epoch 6, loss 0.3964, train acc 0.856, test acc 0.869\n",
      "epoch 7, loss 0.3773, train acc 0.863, test acc 0.870\n",
      "epoch 8, loss 0.3647, train acc 0.867, test acc 0.874\n",
      "epoch 9, loss 0.3546, train acc 0.871, test acc 0.874\n",
      "epoch 10, loss 0.3451, train acc 0.874, test acc 0.881\n",
      "epoch 11, loss 0.3341, train acc 0.876, test acc 0.883\n",
      "epoch 12, loss 0.3285, train acc 0.878, test acc 0.884\n",
      "epoch 13, loss 0.3189, train acc 0.882, test acc 0.887\n",
      "epoch 14, loss 0.3114, train acc 0.885, test acc 0.885\n",
      "epoch 15, loss 0.3032, train acc 0.887, test acc 0.884\n",
      "epoch 16, loss 0.3026, train acc 0.889, test acc 0.889\n",
      "epoch 17, loss 0.2957, train acc 0.890, test acc 0.887\n",
      "epoch 18, loss 0.2902, train acc 0.892, test acc 0.887\n",
      "epoch 19, loss 0.2835, train acc 0.895, test acc 0.892\n",
      "epoch 20, loss 0.2810, train acc 0.895, test acc 0.889\n",
      "epoch 21, loss 0.2758, train acc 0.899, test acc 0.890\n",
      "epoch 22, loss 0.2730, train acc 0.898, test acc 0.893\n",
      "epoch 23, loss 0.2666, train acc 0.901, test acc 0.892\n",
      "epoch 24, loss 0.2651, train acc 0.900, test acc 0.888\n",
      "epoch 25, loss 0.2638, train acc 0.902, test acc 0.891\n",
      "epoch 26, loss 0.2595, train acc 0.903, test acc 0.893\n",
      "epoch 27, loss 0.2544, train acc 0.905, test acc 0.897\n",
      "epoch 28, loss 0.2542, train acc 0.905, test acc 0.894\n",
      "epoch 29, loss 0.2520, train acc 0.906, test acc 0.893\n",
      "epoch 30, loss 0.2454, train acc 0.909, test acc 0.889\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.2),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(0.5),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, 30, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "gluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
