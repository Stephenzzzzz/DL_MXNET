{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:25:44.377325Z",
     "start_time": "2019-05-14T05:25:43.547060Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:27:41.372187Z",
     "start_time": "2019-05-14T05:27:40.817676Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义和初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:28:46.652913Z",
     "start_time": "2019-05-14T05:28:46.646929Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "# 添加输出为10的全连接层\n",
    "net.add(nn.Dense(10))\n",
    "# 使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax和交叉熵损失函数"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "分开定义softmax运算和交叉熵损失函数可能会造成数值不稳定。因此，Gluon提供了一个包括softmax运算和交叉熵损失计算的函数。它的数值稳定性更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:39:13.975865Z",
     "start_time": "2019-05-14T05:39:13.972900Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:36:05.348291Z",
     "start_time": "2019-05-14T05:36:05.341310Z"
    }
   },
   "source": [
    "### 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:37:45.260063Z",
     "start_time": "2019-05-14T05:37:45.256058Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:39:39.282135Z",
     "start_time": "2019-05-14T05:39:14.685842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7911, train acc 0.745, test acc 0.800\n",
      "epoch 2, loss 0.5740, train acc 0.812, test acc 0.823\n",
      "epoch 3, loss 0.5294, train acc 0.823, test acc 0.832\n",
      "epoch 4, loss 0.5057, train acc 0.830, test acc 0.837\n",
      "epoch 5, loss 0.4896, train acc 0.834, test acc 0.839\n"
     ]
    }
   ],
   "source": [
    "# 和上一节一样\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "调参测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:44:24.344058Z",
     "start_time": "2019-05-14T05:43:58.764653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.0778, train acc 0.440, test acc 0.644\n",
      "epoch 2, loss 1.7556, train acc 0.655, test acc 0.660\n",
      "epoch 3, loss 1.5467, train acc 0.665, test acc 0.663\n",
      "epoch 4, loss 1.4025, train acc 0.667, test acc 0.664\n",
      "epoch 5, loss 1.2981, train acc 0.668, test acc 0.666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'25.57 sec'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "net = nn.Sequential()\n",
    "# 添加输出为10的全连接层\n",
    "net.add(nn.Dense(10))\n",
    "# 使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)\n",
    "\n",
    "'%.2f sec' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "学习率太小，5轮还没有收敛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:45:49.987787Z",
     "start_time": "2019-05-14T05:45:23.909522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 18.2983, train acc 0.685, test acc 0.825\n",
      "epoch 2, loss 9.7188, train acc 0.756, test acc 0.820\n",
      "epoch 3, loss 8.6893, train acc 0.772, test acc 0.836\n",
      "epoch 4, loss 8.6708, train acc 0.775, test acc 0.842\n",
      "epoch 5, loss 8.4624, train acc 0.781, test acc 0.820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'26.07 sec'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "net = nn.Sequential()\n",
    "# 添加输出为10的全连接层\n",
    "net.add(nn.Dense(10))\n",
    "# 使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 5})\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)\n",
    "\n",
    "'%.2f sec' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "学习率太大，第4轮就开始收敛，但不是最小值，loss还很大，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T05:58:03.353088Z",
     "start_time": "2019-05-14T05:57:11.067966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.9216, train acc 0.710, test acc 0.779\n",
      "epoch 2, loss 0.6446, train acc 0.792, test acc 0.799\n",
      "epoch 3, loss 0.5856, train acc 0.810, test acc 0.817\n",
      "epoch 4, loss 0.5540, train acc 0.819, test acc 0.825\n",
      "epoch 5, loss 0.5328, train acc 0.824, test acc 0.828\n",
      "epoch 6, loss 0.5182, train acc 0.828, test acc 0.833\n",
      "epoch 7, loss 0.5060, train acc 0.831, test acc 0.831\n",
      "epoch 8, loss 0.4966, train acc 0.833, test acc 0.839\n",
      "epoch 9, loss 0.4896, train acc 0.835, test acc 0.838\n",
      "epoch 10, loss 0.4831, train acc 0.837, test acc 0.840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'52.28 sec'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_size = 512\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "net = nn.Sequential()\n",
    "# 添加输出为10的全连接层\n",
    "net.add(nn.Dense(10))\n",
    "# 使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "num_epochs = 10\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)\n",
    "\n",
    "'%.2f sec' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.batch_size设的大一些，收敛得块，也就是需要训练的次数少，准确率上升的也很稳定，但是实际使用起来精度不高。\n",
    "\n",
    "2.batch_size设的小一些，收敛得慢，可能准确率来回震荡，因此需要把基础学习速率降低一些，但是实际使用起来精度较高。\n",
    "\n",
    "一般尝试batch_size=64或者batch_size=1两种情况\n",
    "\n",
    "知乎用户：理论上说batch_size=1是最好的，不过实际上调的时候，会出现batch_size太小导致网络收敛不稳定，最后结果比较差。而batch_size太大会影响随机性的引入。\n",
    "\n",
    "参考：深度学习中的batch的大小对学习效果有何影响？ - 程引的回答 - 知乎\n",
    "https://www.zhihu.com/question/32673260/answer/71137399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:07:06.235158Z",
     "start_time": "2019-05-14T06:04:28.107993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7888, train acc 0.747, test acc 0.806\n",
      "epoch 2, loss 0.5738, train acc 0.811, test acc 0.820\n",
      "epoch 3, loss 0.5291, train acc 0.823, test acc 0.832\n",
      "epoch 4, loss 0.5041, train acc 0.831, test acc 0.829\n",
      "epoch 5, loss 0.4896, train acc 0.835, test acc 0.839\n",
      "epoch 6, loss 0.4786, train acc 0.838, test acc 0.842\n",
      "epoch 7, loss 0.4690, train acc 0.840, test acc 0.845\n",
      "epoch 8, loss 0.4624, train acc 0.843, test acc 0.841\n",
      "epoch 9, loss 0.4564, train acc 0.844, test acc 0.847\n",
      "epoch 10, loss 0.4508, train acc 0.846, test acc 0.848\n",
      "epoch 11, loss 0.4463, train acc 0.848, test acc 0.851\n",
      "epoch 12, loss 0.4431, train acc 0.848, test acc 0.849\n",
      "epoch 13, loss 0.4401, train acc 0.849, test acc 0.850\n",
      "epoch 14, loss 0.4363, train acc 0.850, test acc 0.846\n",
      "epoch 15, loss 0.4342, train acc 0.850, test acc 0.836\n",
      "epoch 16, loss 0.4331, train acc 0.852, test acc 0.854\n",
      "epoch 17, loss 0.4295, train acc 0.853, test acc 0.854\n",
      "epoch 18, loss 0.4281, train acc 0.854, test acc 0.851\n",
      "epoch 19, loss 0.4257, train acc 0.855, test acc 0.853\n",
      "epoch 20, loss 0.4237, train acc 0.855, test acc 0.854\n",
      "epoch 21, loss 0.4225, train acc 0.854, test acc 0.850\n",
      "epoch 22, loss 0.4215, train acc 0.855, test acc 0.855\n",
      "epoch 23, loss 0.4186, train acc 0.856, test acc 0.857\n",
      "epoch 24, loss 0.4181, train acc 0.856, test acc 0.856\n",
      "epoch 25, loss 0.4162, train acc 0.856, test acc 0.857\n",
      "epoch 26, loss 0.4157, train acc 0.857, test acc 0.856\n",
      "epoch 27, loss 0.4143, train acc 0.858, test acc 0.859\n",
      "epoch 28, loss 0.4129, train acc 0.859, test acc 0.854\n",
      "epoch 29, loss 0.4131, train acc 0.859, test acc 0.857\n",
      "epoch 30, loss 0.4112, train acc 0.859, test acc 0.857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'158.12 sec'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "net = nn.Sequential()\n",
    "# 添加输出为10的全连接层\n",
    "net.add(nn.Dense(10))\n",
    "# 使用均值为0、标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "num_epochs = 30\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)\n",
    "\n",
    "'%.2f sec' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "gluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
